{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8b222c4-09c8-4b7d-9df9-fc36c719a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e5f1125-e1fe-4e8d-a54b-20468370b8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   YEAR  STATE  FLOOD OCCURENCE     RH  MAX_TEMP  MIN_TEMP  PRECIPITATION\n",
      "0  1990  BENUE                0  77.38     35.99     14.08        1165.43\n",
      "1  1990    FCT                0  74.44     38.61     13.43        1270.90\n",
      "2  1990   KOGI                0  77.50     36.12     16.42         949.22\n",
      "3  1990  KWARA                0  68.44     39.73     15.85         849.02\n",
      "4  1990   NASS                0  74.12     38.76     14.87        1244.53\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/user/Desktop/MSc Folder/Graduate Applications/Flood Data/Flood_Data1.csv')\n",
    "\n",
    "# Inspect the first few rows\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dccb7399-41dc-4678-a4f0-96a36c7ec5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   YEAR     RH  MAX_TEMP  MIN_TEMP  PRECIPITATION  STATE_FCT  STATE_KOGI  \\\n",
      "0  1990  77.38     35.99     14.08        1165.43      False       False   \n",
      "1  1990  74.44     38.61     13.43        1270.90       True       False   \n",
      "2  1990  77.50     36.12     16.42         949.22      False        True   \n",
      "3  1990  68.44     39.73     15.85         849.02      False       False   \n",
      "4  1990  74.12     38.76     14.87        1244.53      False       False   \n",
      "\n",
      "   STATE_KWARA  STATE_NASS  STATE_NIGER  STATE_PLATEAU  \n",
      "0        False       False        False          False  \n",
      "1        False       False        False          False  \n",
      "2        False       False        False          False  \n",
      "3         True       False        False          False  \n",
      "4        False        True        False          False  \n"
     ]
    }
   ],
   "source": [
    "# Define the features (X) and target (y)\n",
    "X = data.drop(columns=['FLOOD OCCURENCE'])  # All independent variables\n",
    "y = data['FLOOD OCCURENCE']  # Dependent variable\n",
    "\n",
    "# If 'State' is categorical, you need to encode it\n",
    "X = pd.get_dummies(X, columns=['STATE'], drop_first=True)\n",
    "\n",
    "# Check the processed data\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e446ba38-dee3-45ab-a20b-5bf1c5300728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.83\n",
      "Test accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Retain 'Year' for trend analysis\n",
    "year_column = data['YEAR']\n",
    "\n",
    "#Spliting Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50)\n",
    "\n",
    "#Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameters and their respective values to be tested\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=rf_clf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the corresponding best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "best_model = grid_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Test accuracy: {:.2f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f058e41-90fe-4cb9-85b7-34f62cc8f5b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_absolute_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# y_pred = best_model.predict(X_test)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_test, y_pred)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean Absolute Error on test set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mean_absolute_error' is not defined"
     ]
    }
   ],
   "source": [
    "# y_pred = best_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error on test set: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1fe05-de6b-4077-96d4-56dbfdc5d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate MAPE\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate R-squared (R²)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print the results\n",
    "print(f\"MAPE: {mape:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1337f925-be74-411d-9e0c-15d6d59bd458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "importances = best_model.feature_importances_\n",
    "features = X.columns\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], align='center')\n",
    "plt.yticks(range(len(indices)), features[indices])\n",
    "plt.xlabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e5dd9f-f199-46aa-8bab-6b9badf6178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Compute metrics\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R² (Goodness of Fit): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199bfc4c-b57f-438f-9604-f7046aca1202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate MAPE\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate R-squared (R²)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print the results\n",
    "print(f\"MAPE: {mape:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e4cbd4-6743-4db2-bbb1-2b7cdbddf2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc332b7-4620-4f94-ac81-b48413b56158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe84f5aa-da9f-4e64-a910-4ce6cb98b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine predictions with Year for trend analysis\n",
    "df_test = pd.DataFrame(X_test, columns=X.columns)  # Recreate DataFrame for test data\n",
    "df_test['Year'] = year_test.reset_index(drop=True)  # Add Year back to the test DataFrame\n",
    "df_test['Flood_Prediction'] = y_pred\n",
    "\n",
    "# Group by Year and calculate mean prediction\n",
    "yearly_trend = df_test.groupby('Year')['Flood_Prediction'].mean().reset_index()\n",
    "\n",
    "# Plot the bar chart of predicted flood occurrences over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=yearly_trend, x='Year', y='Flood_Prediction', color='skyblue')\n",
    "plt.title('Trend of Predicted Flood Occurrences Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Predicted Flood Occurrences')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8176bdd1-9444-4f98-860f-057abfa65c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the count of predicted floods and non-floods\n",
    "yearly_flood_counts = df_test.groupby('Year')['Flood_Prediction'].value_counts().unstack().fillna(0).reset_index()\n",
    "yearly_flood_counts.columns = ['Year', 'No Flood', 'Flood']\n",
    "\n",
    "# Plotting the stacked bar chart\n",
    "plt.figure(figsize=(12, 7))\n",
    "yearly_flood_counts.set_index('Year').plot(kind='bar', stacked=True, color=['lightgrey', 'skyblue'])\n",
    "#plt.title('Stacked Bar Plot of Predicted Flood Occurrences vs. Non-Occurrences Over Time')\n",
    "plt.title('Trend Analysis for Flood Predictions')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)  # Rotating x-axis labels for better readability\n",
    "plt.legend(title='Prediction')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7eb081-e85d-4b72-8718-5ec23ce40d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table for heatmap\n",
    "heatmap_data = df_test.groupby(['Year', 'Flood_Prediction']).size().unstack().fillna(0)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.heatmap(heatmap_data, cmap='Blues', annot=True, cbar_kws={'label': 'Count'})\n",
    "plt.title('Heatmap of Predicted Flood Occurrences and Non-Occurrences Over Time')\n",
    "plt.xlabel('Flood Prediction')\n",
    "plt.ylabel('Year')\n",
    "plt.xticks(ticks=[0.5, 1.5], labels=['No Flood', 'Flood'])\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67948635-06c4-4ce0-be7b-20358cf888f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the count of predicted floods and non-floods\n",
    "yearly_flood_counts = df_test.groupby('Year')['Flood_Prediction'].value_counts().unstack().fillna(0).reset_index()\n",
    "yearly_flood_counts.columns = ['Year', 'No Flood', 'Flood']\n",
    "\n",
    "# Plot the area plot\n",
    "plt.figure(figsize=(12, 7))\n",
    "yearly_flood_counts.set_index('Year').plot(kind='area', stacked=True, alpha=0.5, color=['lightgrey', 'skyblue'])\n",
    "plt.title('Area Plot of Predicted Flood Occurrences and Non-Occurrences Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38d06c1-5556-40f3-a702-3b48e9648bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for stacked line plot\n",
    "yearly_flood_counts = df_test.groupby(['Year', 'Flood_Prediction']).size().unstack().fillna(0).cumsum().reset_index()\n",
    "\n",
    "# Plot stacked line plot\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.plot(yearly_flood_counts['Year'], yearly_flood_counts[0], label='No Flood', color='lightgrey')\n",
    "plt.plot(yearly_flood_counts['Year'], yearly_flood_counts[1], label='Flood', color='skyblue')\n",
    "plt.fill_between(yearly_flood_counts['Year'], yearly_flood_counts[0], color='lightgrey', alpha=0.5)\n",
    "plt.fill_between(yearly_flood_counts['Year'], yearly_flood_counts[1], color='skyblue', alpha=0.5)\n",
    "plt.title('Stacked Line Plot of Predicted Flood Occurrences and Non-Occurrences Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Cumulative Count')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a1610-804e-413b-a359-a57af8757ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume y_true and y_pred are your true labels and predicted labels respectively\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Extract True Positives (TP) and False Negatives (FN)\n",
    "TP = cm[1, 1]\n",
    "FN = cm[1, 0]\n",
    "\n",
    "# Calculate Sensitivity\n",
    "sensitivity = TP / (TP + FN)\n",
    "print(f\"Sensitivity: {sensitivity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9013f-f4cd-44d6-8205-1eb68b36cae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641df7b5-9831-4f7e-865d-dacb1ed03185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Compute Precision-Recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(recall, precision, color='blue', label='Precision-Recall curve')\n",
    "plt.xlabel('Recall (Sensitivity)')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='lower left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f7439e-95f1-493f-aa34-8ba2f8ef0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "# Plot Sensitivity (TPR) vs. (1 - Specificity)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(thresholds, tpr, color='blue', label='Sensitivity')\n",
    "plt.plot(thresholds, 1-fpr, color='red', label='Specificity')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Sensitivity and Specificity vs. Threshold')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b55985-d99f-4fcd-8b96-4faa075cbd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_test, label='Actual Values', marker='o')\n",
    "plt.plot(y_pred, label='Predicted Values', marker='x')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
